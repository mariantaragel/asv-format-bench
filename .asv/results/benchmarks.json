{
    "Compression.time_read": {
        "code": "class Compression:\n    def time_read(self, format, ds, compression, complevel):\n        \"\"\"Run compression benchmark read time\"\"\"\n        format.read()\n\n    def setup(self, format, ds, compression, complevel):\n        \"\"\"Benchmark setup\"\"\"\n        format.save(ds.df, compression, complevel)",
        "min_run_count": 2,
        "name": "Compression.time_read",
        "number": 0,
        "param_names": [
            "Data format",
            "Dataset",
            "Compression",
            "Compression level"
        ],
        "params": [
            [
                "HDF5.table",
                "Parquet",
                "Feather",
                "ORC"
            ],
            [
                "eq"
            ],
            [
                "'lz4'",
                "'zstd'"
            ],
            [
                "1"
            ]
        ],
        "pretty_name": "Reading time",
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 140,
        "type": "time",
        "unit": "seconds",
        "version": "c5883f8f730b8b8f4b08cbb5164e839e56c7688df653ed5ccfdde77a13250aa8",
        "warmup_time": -1
    },
    "Compression.time_save": {
        "code": "class Compression:\n    def time_save(self, format, ds, compression, complevel):\n        \"\"\"Run compression benchmark save time\"\"\"\n        format.save(ds.df, compression, complevel)\n\n    def setup(self, format, ds, compression, complevel):\n        \"\"\"Benchmark setup\"\"\"\n        format.save(ds.df, compression, complevel)",
        "min_run_count": 2,
        "name": "Compression.time_save",
        "number": 0,
        "param_names": [
            "Data format",
            "Dataset",
            "Compression",
            "Compression level"
        ],
        "params": [
            [
                "HDF5.table",
                "Parquet",
                "Feather",
                "ORC"
            ],
            [
                "eq"
            ],
            [
                "'lz4'",
                "'zstd'"
            ],
            [
                "1"
            ]
        ],
        "pretty_name": "Saving time",
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 140,
        "type": "time",
        "unit": "seconds",
        "version": "bfe47e029b7bcf647efa40519b748c4f7cb4235ddcaacd43cb4ed1441caab333",
        "warmup_time": -1
    },
    "Compression.track_size": {
        "code": "class Compression:\n    def track_size(self, format, ds, compression, complevel):\n        \"\"\"Run compression benchmark total size\"\"\"\n        return format.size()\n\n    def setup(self, format, ds, compression, complevel):\n        \"\"\"Benchmark setup\"\"\"\n        format.save(ds.df, compression, complevel)",
        "name": "Compression.track_size",
        "param_names": [
            "Data format",
            "Dataset",
            "Compression",
            "Compression level"
        ],
        "params": [
            [
                "HDF5.table",
                "Parquet",
                "Feather",
                "ORC"
            ],
            [
                "eq"
            ],
            [
                "'lz4'",
                "'zstd'"
            ],
            [
                "1"
            ]
        ],
        "pretty_name": "Total size",
        "timeout": 140,
        "type": "memory",
        "unit": "bytes",
        "version": "f40ce7ddee4596cbc62b521ba7101e458dd1924ae47b884c4cb3993e2463f12d"
    },
    "Image.time_read": {
        "code": "class Image:\n    def time_read(self, format, ds):\n        \"\"\"Run image benchmark total size\"\"\"\n        format.read()\n\n    def setup(self, format, ds):\n        \"\"\"Benchmark setup\"\"\"\n        format.save(ds.images, ds.labels)",
        "min_run_count": 2,
        "name": "Image.time_read",
        "number": 0,
        "param_names": [
            "Data format",
            "Dataset"
        ],
        "params": [
            [
                "PNG",
                "Base64",
                "HDF5",
                "Parquet",
                "SQLite",
                "LMDB"
            ],
            [
                "Cifar-10"
            ]
        ],
        "pretty_name": "Reading time",
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 2200,
        "type": "time",
        "unit": "seconds",
        "version": "c62868977e94090a84ef205b285a0ffc716de3b2b3d5b3da89c69930d623f433",
        "warmup_time": -1
    },
    "Image.time_save": {
        "code": "class Image:\n    def time_save(self, format, ds):\n        \"\"\"Run image benchmark save time\"\"\"\n        format.save(ds.images, ds.labels)\n\n    def setup(self, format, ds):\n        \"\"\"Benchmark setup\"\"\"\n        format.save(ds.images, ds.labels)",
        "min_run_count": 2,
        "name": "Image.time_save",
        "number": 0,
        "param_names": [
            "Data format",
            "Dataset"
        ],
        "params": [
            [
                "PNG",
                "Base64",
                "HDF5",
                "Parquet",
                "SQLite",
                "LMDB"
            ],
            [
                "Cifar-10"
            ]
        ],
        "pretty_name": "Saving time",
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 2200,
        "type": "time",
        "unit": "seconds",
        "version": "5ae6893b81ab2812f2b37db0ea152197cc6b364a4ba722e08aa152937601dbc1",
        "warmup_time": -1
    },
    "Image.track_size": {
        "code": "class Image:\n    def track_size(self, format, ds):\n        \"\"\"Run image benchmark read time\"\"\"\n        return format.size()\n\n    def setup(self, format, ds):\n        \"\"\"Benchmark setup\"\"\"\n        format.save(ds.images, ds.labels)",
        "name": "Image.track_size",
        "param_names": [
            "Data format",
            "Dataset"
        ],
        "params": [
            [
                "PNG",
                "Base64",
                "HDF5",
                "Parquet",
                "SQLite",
                "LMDB"
            ],
            [
                "Cifar-10"
            ]
        ],
        "pretty_name": "Total size",
        "timeout": 2200,
        "type": "memory",
        "unit": "bytes",
        "version": "2bebe2a879b39db9e484b53a3c4c87ccd581b2790947d59d8e2bd5af2d84cd29"
    },
    "Tabular.time_read": {
        "code": "class Tabular:\n    def time_read(self, format, ds):\n        \"\"\"Run tabular benchmark read time\"\"\"\n        format.read()\n\n    def setup(self, format, ds):\n        \"\"\"Benchmark setup\"\"\"\n        format.save(ds.df)",
        "min_run_count": 2,
        "name": "Tabular.time_read",
        "number": 0,
        "param_names": [
            "Data format",
            "Dataset"
        ],
        "params": [
            [
                "CSV",
                "JSON",
                "XML",
                "HDF5.fixed",
                "HDF5.table",
                "Parquet",
                "Feather",
                "ORC",
                "Pickle",
                "Excel",
                "Lance",
                "Avro"
            ],
            [
                "eq",
                "int",
                "float",
                "bool",
                "str"
            ]
        ],
        "pretty_name": "Reading time",
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "b64d6b2eb6f0ed4d63d9fe79ba98c5db87a70a3e4f03bf6a9c3bae999cfb8465",
        "warmup_time": -1
    },
    "Tabular.time_save": {
        "code": "class Tabular:\n    def time_save(self, format, ds):\n        \"\"\"Run tabular benchmark save time\"\"\"\n        format.save(ds.df)\n\n    def setup(self, format, ds):\n        \"\"\"Benchmark setup\"\"\"\n        format.save(ds.df)",
        "min_run_count": 2,
        "name": "Tabular.time_save",
        "number": 0,
        "param_names": [
            "Data format",
            "Dataset"
        ],
        "params": [
            [
                "CSV",
                "JSON",
                "XML",
                "HDF5.fixed",
                "HDF5.table",
                "Parquet",
                "Feather",
                "ORC",
                "Pickle",
                "Excel",
                "Lance",
                "Avro"
            ],
            [
                "eq",
                "int",
                "float",
                "bool",
                "str"
            ]
        ],
        "pretty_name": "Saving time",
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "a2ba64ff6161372a79d14eef3a81902fcc80f726d0f290e6ac42c2335b191fee",
        "warmup_time": -1
    },
    "Tabular.track_size": {
        "code": "class Tabular:\n    def track_size(self, format, ds):\n        \"\"\"Run tabular benchmark total size\"\"\"\n        return format.size()\n\n    def setup(self, format, ds):\n        \"\"\"Benchmark setup\"\"\"\n        format.save(ds.df)",
        "name": "Tabular.track_size",
        "param_names": [
            "Data format",
            "Dataset"
        ],
        "params": [
            [
                "CSV",
                "JSON",
                "XML",
                "HDF5.fixed",
                "HDF5.table",
                "Parquet",
                "Feather",
                "ORC",
                "Pickle",
                "Excel",
                "Lance",
                "Avro"
            ],
            [
                "eq",
                "int",
                "float",
                "bool",
                "str"
            ]
        ],
        "pretty_name": "Total size",
        "timeout": 500,
        "type": "memory",
        "unit": "bytes",
        "version": "67f1d099a81532e3b9a5fb4e93e51c55294c191452ea2a0c239d9f7dc36ec215"
    },
    "version": 2
}